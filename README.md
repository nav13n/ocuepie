Problem Statement: Accommodation Search. 

Detail: 

You log onto a website, sort all the homes, see pictures, budget and amenities , sort a set of homes and make a list but as soon as you arrive at the prospected house, all that info is lost. You have all those pictures and data only in your mind. There is a diff in what you see and what you get. There is no way to quickly validate and compare. There is no way to leave a feedback for others. 

For differently abled people, Its worse, there is no way to experience the home and there is no way to navigate inside that.

Solution: The app uses BLE tags to bind and associate information inside and outside house. It leverage BLE's and mobstac SDK's publishing capabilities for contextual information delivery right where it is needed and allows for a better user experienced and informed decision making. 

Access to the context also allows for a more personalised information delivery building better connect with people.

It also exploits BLE's indoor navigation capabilities to assist differently abled people to navigate and roam around the house opening a unexplored user base.

And at last, It allows people to search the best personal fit using augmented reality.

In short, the key features and differentiator of the app are:

1)Pushes rather fishes information.
2)Assisted navigation for the differently-abled.
3)Allows to validate, compare and give feedback.
4)Information with a human touch.
5)Personalisation mapping the physical and real world.
